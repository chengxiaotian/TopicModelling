{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import col,when,size,min, max,length\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]')\\\n",
    "    .appName('topic_modelling')\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet(\"part-00000-a8a717e8-bf83-42e3-a0b7-084971053d99-c000.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column and put in the detected language code\n",
    "from langdetect import detect\n",
    "getCode = lambda x:detect(x)\n",
    "sent = \"this is eng\"\n",
    "getCode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>bundle</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>os_platform</th>\n",
       "      <th>lang_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Box - Movie Listing</td>\n",
       "      <td>958957112</td>\n",
       "      <td>Black Box Movie Listing App is a collection li...</td>\n",
       "      <td>[Entertainment, Magazines &amp; Newspapers]</td>\n",
       "      <td>IOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knife Throwing Max</td>\n",
       "      <td>1491396285</td>\n",
       "      <td>you will have fun in this game\\n100+ challengi...</td>\n",
       "      <td>[Games_Sports, Games_Role Playing]</td>\n",
       "      <td>IOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÁàÜÊñôÂÖ¨Á§æ</td>\n",
       "      <td>1387765782</td>\n",
       "      <td>ÂÖ®Âè∞ÊúÄÂ§ßÁ§æÁæ§„ÄåÁàÜÊñôÂÖ¨Á§æ„ÄçAPP ‰∏äÁ∑öÂï¶ÔºåÊàëÂÄëÊääÁ§æÁæ§Ëß£Êîæ‰∫ÜÔºå‰∏çÂè™ÊúâÂãÅÁàÜÁöÑÁàÜÊñôÂÖßÂÆπÔºåÈÇÑË≤ºÂøÉÁöÑÂä†‰∏ä...</td>\n",
       "      <td>[Social Networking]</td>\n",
       "      <td>IOS</td>\n",
       "      <td>zh-tw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lidow - Photo Editor &amp; Collage</td>\n",
       "      <td>894532288</td>\n",
       "      <td>layout/grid/collage„ÄÅSquare/no crop for instagr...</td>\n",
       "      <td>[Photo &amp; Video]</td>\n",
       "      <td>IOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vidstitch Frames for Instagram</td>\n",
       "      <td>712908978</td>\n",
       "      <td>‚ñ† #Vidstitch\\n‚ñ† Featured on 148apps, Stelapps,...</td>\n",
       "      <td>[Photo &amp; Video, Social Networking]</td>\n",
       "      <td>IOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Barber Hair Salon &amp; Beard Makeover</td>\n",
       "      <td>com.hmg.haircutgames.beardsalon.barberhaircut</td>\n",
       "      <td>Barber hair makeover salon game is for those w...</td>\n",
       "      <td>[ENTERTAINMENT, FAMILY_PRETEND]</td>\n",
       "      <td>ANDROID</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>DJ Remix Offline 2020</td>\n",
       "      <td>com.mpro.djremixoffline2020</td>\n",
       "      <td>Dj Remix Offline 2020 Mp3 merupakan aplikasi m...</td>\n",
       "      <td>[MUSIC_AND_AUDIO]</td>\n",
       "      <td>ANDROID</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Sahih Bukhari (English)</td>\n",
       "      <td>com.bangladroid.sahihbukhari</td>\n",
       "      <td>We have made this application from the book of...</td>\n",
       "      <td>[BOOKS_AND_REFERENCE]</td>\n",
       "      <td>ANDROID</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Two Minute English</td>\n",
       "      <td>com.astrobix.twominuteenglish</td>\n",
       "      <td>Improve your spoken English rapidly with the h...</td>\n",
       "      <td>[EDUCATION]</td>\n",
       "      <td>ANDROID</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>Galaxy S9 purple Theme</td>\n",
       "      <td>com.thegosa.s9purplefreetheme</td>\n",
       "      <td>Now this application is a full theme for all s...</td>\n",
       "      <td>[PERSONALIZATION]</td>\n",
       "      <td>ANDROID</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>865 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               app_name  \\\n",
       "0             Black Box - Movie Listing   \n",
       "1                    Knife Throwing Max   \n",
       "2                                  ÁàÜÊñôÂÖ¨Á§æ   \n",
       "3        Lidow - Photo Editor & Collage   \n",
       "4        Vidstitch Frames for Instagram   \n",
       "..                                  ...   \n",
       "860  Barber Hair Salon & Beard Makeover   \n",
       "861               DJ Remix Offline 2020   \n",
       "862             Sahih Bukhari (English)   \n",
       "863                  Two Minute English   \n",
       "864              Galaxy S9 purple Theme   \n",
       "\n",
       "                                            bundle  \\\n",
       "0                                        958957112   \n",
       "1                                       1491396285   \n",
       "2                                       1387765782   \n",
       "3                                        894532288   \n",
       "4                                        712908978   \n",
       "..                                             ...   \n",
       "860  com.hmg.haircutgames.beardsalon.barberhaircut   \n",
       "861                    com.mpro.djremixoffline2020   \n",
       "862                   com.bangladroid.sahihbukhari   \n",
       "863                  com.astrobix.twominuteenglish   \n",
       "864                  com.thegosa.s9purplefreetheme   \n",
       "\n",
       "                                           description  \\\n",
       "0    Black Box Movie Listing App is a collection li...   \n",
       "1    you will have fun in this game\\n100+ challengi...   \n",
       "2    ÂÖ®Âè∞ÊúÄÂ§ßÁ§æÁæ§„ÄåÁàÜÊñôÂÖ¨Á§æ„ÄçAPP ‰∏äÁ∑öÂï¶ÔºåÊàëÂÄëÊääÁ§æÁæ§Ëß£Êîæ‰∫ÜÔºå‰∏çÂè™ÊúâÂãÅÁàÜÁöÑÁàÜÊñôÂÖßÂÆπÔºåÈÇÑË≤ºÂøÉÁöÑÂä†‰∏ä...   \n",
       "3    layout/grid/collage„ÄÅSquare/no crop for instagr...   \n",
       "4    ‚ñ† #Vidstitch\\n‚ñ† Featured on 148apps, Stelapps,...   \n",
       "..                                                 ...   \n",
       "860  Barber hair makeover salon game is for those w...   \n",
       "861  Dj Remix Offline 2020 Mp3 merupakan aplikasi m...   \n",
       "862  We have made this application from the book of...   \n",
       "863  Improve your spoken English rapidly with the h...   \n",
       "864  Now this application is a full theme for all s...   \n",
       "\n",
       "                                      genres os_platform lang_code  \n",
       "0    [Entertainment, Magazines & Newspapers]         IOS        en  \n",
       "1         [Games_Sports, Games_Role Playing]         IOS        en  \n",
       "2                        [Social Networking]         IOS     zh-tw  \n",
       "3                            [Photo & Video]         IOS        en  \n",
       "4         [Photo & Video, Social Networking]         IOS        en  \n",
       "..                                       ...         ...       ...  \n",
       "860          [ENTERTAINMENT, FAMILY_PRETEND]     ANDROID        en  \n",
       "861                        [MUSIC_AND_AUDIO]     ANDROID        id  \n",
       "862                    [BOOKS_AND_REFERENCE]     ANDROID        en  \n",
       "863                              [EDUCATION]     ANDROID        en  \n",
       "864                        [PERSONALIZATION]     ANDROID        en  \n",
       "\n",
       "[865 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column and put in the detected language code\n",
    "from langdetect import detect\n",
    "# app_name_result = df_parquet.select(col('description')).collect()\n",
    "# # create udf function to add a new column\n",
    "# import pyspark.sql.functions as F\n",
    "# from pyspark.sql.types import *\n",
    "\n",
    "# def detect_lang(value):\n",
    "#   return detect(value)\n",
    "\n",
    "# #convert to a UDF Function by passing in the function and return type of function\n",
    "# udf_detect_lang = F.udf(detect_lang, StringType())\n",
    "# df_with_code = df_parquet.withColumn('lang_code', udf_detect_lang(df_parquet.description))\n",
    "# df_with_code.show(5)\n",
    "\n",
    "# easier method to convert to pandas then apply then function\n",
    "df_parquet_pd = df_parquet.toPandas()\n",
    "df_parquet_pd['lang_code'] = df_parquet_pd['description'].apply(getCode)\n",
    "df_parquet_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load with only English data\n",
    "df_parquet_en = df_parquet_pd.loc[df_parquet_pd['lang_code']=='en']\n",
    "df_parquet_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_parquet_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----------+---------+--------------------+\n",
      "|            app_name|              bundle|         description|              genres|os_platform|lang_code|   description_clean|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+---------+--------------------+\n",
      "|Black Box - Movie...|           958957112|Black Box Movie L...|[Entertainment, M...|        IOS|       en|Black Box Movie L...|\n",
      "|  Knife Throwing Max|          1491396285|you will have fun...|[Games_Sports, Ga...|        IOS|       en|you will have fun...|\n",
      "|Lidow - Photo Edi...|           894532288|layout/grid/colla...|     [Photo & Video]|        IOS|       en|layout grid colla...|\n",
      "|Vidstitch Frames ...|           712908978|‚ñ† #Vidstitch\n",
      "‚ñ† Fe...|[Photo & Video, S...|        IOS|       en|‚ñ†  Vidstitch\n",
      "‚ñ† Fe...|\n",
      "|Where's my Cat? -...|          1259238703|The cat is hiding...|[Entertainment, G...|        IOS|       en|The cat is hiding...|\n",
      "|Martial Art Wallp...|com.martialart.wa...|Martial arts are ...|   [PERSONALIZATION]|    ANDROID|       en|Martial arts are ...|\n",
      "|      Image detector|com.saryelgmal.se...|Google image sear...|             [TOOLS]|    ANDROID|       en|Google image sear...|\n",
      "|Horoscope - Face ...|com.ocean.horosco...|Your face reveals...|         [LIFESTYLE]|    ANDROID|       en|Your face reveals...|\n",
      "|Neon Pastel Heart...|com.ikeyboard.the...|üíå\n",
      "Neon Pastel He...|   [PERSONALIZATION]|    ANDROID|       en|üíå\n",
      "Neon Pastel He...|\n",
      "|Arabic Voice Typi...|com.worthy.apps.a...|‚≠ï Arabic Voice Ke...|             [TOOLS]|    ANDROID|       en|‚≠ï Arabic Voice Ke...|\n",
      "|Document Scanner ...|   com.cv.docscanner|Sometimes in a si...|      [PRODUCTIVITY]|    ANDROID|       en|Sometimes in a si...|\n",
      "|Vob To Mp4 Video ...|    grant.vob.to.mp4|Easy to use tool ...|     [VIDEO_PLAYERS]|    ANDROID|       en|Easy to use tool ...|\n",
      "|satfinder, Tv Sat...|com.afnan.satfind...|Finding a TV sate...|             [TOOLS]|    ANDROID|       en|Finding a TV sate...|\n",
      "|Chat with sasha &...|   com.sasha.maxchat|If you are a grea...|   [GAME_SIMULATION]|    ANDROID|       en|If you are a grea...|\n",
      "|             Chess 2|com.onecwireless....|Play new, easy to...|        [GAME_BOARD]|    ANDROID|       en|Play new  easy to...|\n",
      "|Merge Airplane Id...|com.pf.idleplane....|Click, merge & de...|   [GAME_SIMULATION]|    ANDROID|       en|Click  merge   de...|\n",
      "|Date-me - Free Da...|  com.dateme.android|Date-me gets you ...|            [SOCIAL]|    ANDROID|       en|Date me gets you ...|\n",
      "|Software Engineering|com.faadooenginee...|The app is a comp...|         [EDUCATION]|    ANDROID|       en|The app is a comp...|\n",
      "|Multi FB - Multi ...|multiple.accounts...|Want to login mul...|            [SOCIAL]|    ANDROID|       en|Want to login mul...|\n",
      "|Walktrough: Resid...|com.guideforresid...|Informations, Tip...|         [EDUCATION]|    ANDROID|       en|Informations  Tip...|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Text cleasing with punctuations\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "REGEX = '[_,\\\\-.!?@#$%^&*+/\\d]'\n",
    "df_spark = df_spark.withColumn(\"description_clean\",regexp_replace(df_spark.description,REGEX,' '))\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----------+---------+--------------------+--------------------+\n",
      "|            app_name|              bundle|         description|              genres|os_platform|lang_code|   description_clean|   description_token|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+---------+--------------------+--------------------+\n",
      "|Black Box - Movie...|           958957112|Black Box Movie L...|[Entertainment, M...|        IOS|       en|Black Box Movie L...|[black, box, movi...|\n",
      "|  Knife Throwing Max|          1491396285|you will have fun...|[Games_Sports, Ga...|        IOS|       en|you will have fun...|[you, will, have,...|\n",
      "|Lidow - Photo Edi...|           894532288|layout/grid/colla...|     [Photo & Video]|        IOS|       en|layout grid colla...|[layout, grid, co...|\n",
      "|Vidstitch Frames ...|           712908978|‚ñ† #Vidstitch\n",
      "‚ñ† Fe...|[Photo & Video, S...|        IOS|       en|‚ñ†  Vidstitch\n",
      "‚ñ† Fe...|[‚ñ†, , vidstitch, ...|\n",
      "|Where's my Cat? -...|          1259238703|The cat is hiding...|[Entertainment, G...|        IOS|       en|The cat is hiding...|[the, cat, is, hi...|\n",
      "|Martial Art Wallp...|com.martialart.wa...|Martial arts are ...|   [PERSONALIZATION]|    ANDROID|       en|Martial arts are ...|[martial, arts, a...|\n",
      "|      Image detector|com.saryelgmal.se...|Google image sear...|             [TOOLS]|    ANDROID|       en|Google image sear...|[google, image, s...|\n",
      "|Horoscope - Face ...|com.ocean.horosco...|Your face reveals...|         [LIFESTYLE]|    ANDROID|       en|Your face reveals...|[your, face, reve...|\n",
      "|Neon Pastel Heart...|com.ikeyboard.the...|üíå\n",
      "Neon Pastel He...|   [PERSONALIZATION]|    ANDROID|       en|üíå\n",
      "Neon Pastel He...|[üíå, neon, pastel...|\n",
      "|Arabic Voice Typi...|com.worthy.apps.a...|‚≠ï Arabic Voice Ke...|             [TOOLS]|    ANDROID|       en|‚≠ï Arabic Voice Ke...|[‚≠ï, arabic, voice...|\n",
      "|Document Scanner ...|   com.cv.docscanner|Sometimes in a si...|      [PRODUCTIVITY]|    ANDROID|       en|Sometimes in a si...|[sometimes, in, a...|\n",
      "|Vob To Mp4 Video ...|    grant.vob.to.mp4|Easy to use tool ...|     [VIDEO_PLAYERS]|    ANDROID|       en|Easy to use tool ...|[easy, to, use, t...|\n",
      "|satfinder, Tv Sat...|com.afnan.satfind...|Finding a TV sate...|             [TOOLS]|    ANDROID|       en|Finding a TV sate...|[finding, a, tv, ...|\n",
      "|Chat with sasha &...|   com.sasha.maxchat|If you are a grea...|   [GAME_SIMULATION]|    ANDROID|       en|If you are a grea...|[if, you, are, a,...|\n",
      "|             Chess 2|com.onecwireless....|Play new, easy to...|        [GAME_BOARD]|    ANDROID|       en|Play new  easy to...|[play, new, , eas...|\n",
      "|Merge Airplane Id...|com.pf.idleplane....|Click, merge & de...|   [GAME_SIMULATION]|    ANDROID|       en|Click  merge   de...|[click, , merge, ...|\n",
      "|Date-me - Free Da...|  com.dateme.android|Date-me gets you ...|            [SOCIAL]|    ANDROID|       en|Date me gets you ...|[date, me, gets, ...|\n",
      "|Software Engineering|com.faadooenginee...|The app is a comp...|         [EDUCATION]|    ANDROID|       en|The app is a comp...|[the, app, is, a,...|\n",
      "|Multi FB - Multi ...|multiple.accounts...|Want to login mul...|            [SOCIAL]|    ANDROID|       en|Want to login mul...|[want, to, login,...|\n",
      "|Walktrough: Resid...|com.guideforresid...|Informations, Tip...|         [EDUCATION]|    ANDROID|       en|Informations  Tip...|[informations, , ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2. Tokenization\n",
    "# df_spark = df_spark.drop(\"description_token\")\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol='description_clean',outputCol='description_token')\n",
    "df_spark = tokenizer.transform(df_spark)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ChengXiaotian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "# from nltk.stem.porter import *\n",
    "# # Instantiate stemmer object\n",
    "# stemmer = PorterStemmer()\n",
    "# stemF = lambda x:stemmer.stem(x)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "import array as arr \n",
    "\n",
    "def lemm_function(list):\n",
    "    list_clean = []\n",
    "    for item in list:\n",
    "        list_clean.append(lemmatizer.lemmatize(item))\n",
    "        \n",
    "    return list_clean\n",
    "    \n",
    "udf_lemm_function= F.udf(lemm_function, ArrayType(StringType()))\n",
    "\n",
    "df_spark = df_spark.withColumn(\"description_lemm\",udf_lemm_function(df_spark.description_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|    description_lemm|\n",
      "+--------------------+\n",
      "|[black, box, movi...|\n",
      "|[you, will, have,...|\n",
      "|[layout, grid, co...|\n",
      "|[‚ñ†, , vidstitch, ...|\n",
      "|[the, cat, is, hi...|\n",
      "|[martial, art, ar...|\n",
      "|[google, image, s...|\n",
      "|[your, face, reve...|\n",
      "|[üíå, neon, pastel...|\n",
      "|[‚≠ï, arabic, voice...|\n",
      "|[sometimes, in, a...|\n",
      "|[easy, to, use, t...|\n",
      "|[finding, a, tv, ...|\n",
      "|[if, you, are, a,...|\n",
      "|[play, new, , eas...|\n",
      "|[click, , merge, ...|\n",
      "|[date, me, get, y...|\n",
      "|[the, app, is, a,...|\n",
      "|[want, to, login,...|\n",
      "|[information, , t...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(\"description_lemm\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Remove stopword\n",
    "# df_spark = df_spark.drop(\"description_no_stop\")\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "import numpy as np\n",
    "\n",
    "stopwords_list = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stopwords_customize_list = [\"app\",\"apps\"]\n",
    "stopwords_list = np.append(stopwords_list,stopwords_customize_list)\n",
    "\n",
    "stopwords = StopWordsRemover(inputCol=\"description_lemm\",outputCol=\"description_no_stop\",stopWords=stopwords_list)\n",
    "stopwords.getStopWords()\n",
    "df_spark = stopwords.transform(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_desc_final = df_spark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_desc_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: IDF vector must be trained with large corpus, otherwise lose the advance of IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the \"description\" column\n",
    "joinF= lambda x:\" \".join(x)\n",
    "df_pd_desc_final[\"description_join\"] = df_pd_desc_final[\"description_no_stop\"].apply(joinF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = df_pd_desc_final[\"description_join\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. TF-IDF countvector, Transform documents to document-term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_df=0.95) #ignore terms that have a document frequency strictly higher than the given threshold\n",
    "dtm = cv.fit_transform(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aac',\n",
       " 'aap',\n",
       " 'aapake',\n",
       " 'aapko',\n",
       " 'aarti',\n",
       " 'ab',\n",
       " 'abacus',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'ability',\n",
       " 'ablar',\n",
       " 'able',\n",
       " 'ablution',\n",
       " 'abnormal',\n",
       " 'aboard',\n",
       " 'aboki',\n",
       " 'about',\n",
       " 'aboutads',\n",
       " 'aboutus',\n",
       " 'above',\n",
       " 'abraxas',\n",
       " 'abreast',\n",
       " 'abridged',\n",
       " 'abroad',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abu',\n",
       " 'abundant',\n",
       " 'abx',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'acca',\n",
       " 'accelerate',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accelerometer',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'acclaim',\n",
       " 'accolade',\n",
       " 'accompanied',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplishment',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'ace',\n",
       " 'ach',\n",
       " 'acharya',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'acid',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acquired',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adaptable',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adb',\n",
       " 'adchoices',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'addons',\n",
       " 'address',\n",
       " 'adelaide',\n",
       " 'adequate',\n",
       " 'adha',\n",
       " 'adhd',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjusts',\n",
       " 'admin',\n",
       " 'administered',\n",
       " 'administrator',\n",
       " 'admirably',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adrenaline',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventuring',\n",
       " 'adversary',\n",
       " 'adversely',\n",
       " 'advertise',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisor',\n",
       " 'adw',\n",
       " 'aed',\n",
       " 'aerial',\n",
       " 'aero',\n",
       " 'aerobatic',\n",
       " 'aerobatics',\n",
       " 'aerodrome',\n",
       " 'aerodynamics',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affiliated',\n",
       " 'afford',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'afghanistan',\n",
       " 'afk',\n",
       " 'afn',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'after',\n",
       " 'afterbirth',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'aggressive',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'agitated',\n",
       " 'agmikor',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'agusta',\n",
       " 'ah',\n",
       " 'ahadeeth',\n",
       " 'ahead',\n",
       " 'ahlam',\n",
       " 'ahoy',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aikido',\n",
       " 'aileron',\n",
       " 'ailerons',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aiport',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'airbrush',\n",
       " 'aircraft',\n",
       " 'airing',\n",
       " 'airline',\n",
       " 'airpak',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airsim',\n",
       " 'aisle',\n",
       " 'ak',\n",
       " 'akshaya',\n",
       " 'al',\n",
       " 'alafasy',\n",
       " 'alamate',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarms',\n",
       " 'alaska',\n",
       " 'albanian',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcatel',\n",
       " 'alchemy',\n",
       " 'alcoholic',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alertness',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'algebra',\n",
       " 'algeria',\n",
       " 'algerian',\n",
       " 'algorithm',\n",
       " 'alictus',\n",
       " 'alien',\n",
       " 'alighnment',\n",
       " 'aligned',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alim',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alladvices',\n",
       " 'allah',\n",
       " 'allen',\n",
       " 'allergen',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'alliance',\n",
       " 'allies',\n",
       " 'allo',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allshowdown',\n",
       " 'allways',\n",
       " 'ally',\n",
       " 'almanac',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'aloud',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alphabetic',\n",
       " 'alphabetical',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altimeter',\n",
       " 'altitude',\n",
       " 'altruism',\n",
       " 'always',\n",
       " 'amader',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambedkar',\n",
       " 'ambiance',\n",
       " 'ambient',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'amd',\n",
       " 'amen',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americos',\n",
       " 'americostech',\n",
       " 'amharic',\n",
       " 'ammo',\n",
       " 'ammunition',\n",
       " 'amoled',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'ample',\n",
       " 'amrap',\n",
       " 'amsterdam',\n",
       " 'amuse',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amzvn',\n",
       " 'an',\n",
       " 'anagram',\n",
       " 'analog',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzing',\n",
       " 'anantapur',\n",
       " 'anatomical',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'andaman',\n",
       " 'anddev',\n",
       " 'andersen',\n",
       " 'andhra',\n",
       " 'andreas',\n",
       " 'andriod',\n",
       " 'android',\n",
       " 'anecdote',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'anglicized',\n",
       " 'angling',\n",
       " 'angolan',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animate',\n",
       " 'animated',\n",
       " 'animating',\n",
       " 'animation',\n",
       " 'animator',\n",
       " 'animatronics',\n",
       " 'anime',\n",
       " 'anjaam',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'anniversary',\n",
       " 'annotate',\n",
       " 'annotation',\n",
       " 'announced',\n",
       " 'announcer',\n",
       " 'announces',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'anonymous',\n",
       " 'anonymously',\n",
       " 'another',\n",
       " 'ansaar',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'ant',\n",
       " 'antelope',\n",
       " 'antena',\n",
       " 'antenna',\n",
       " 'anti',\n",
       " 'antibirth',\n",
       " 'antidepressant',\n",
       " 'antillean',\n",
       " 'antiquity',\n",
       " 'antivirus',\n",
       " 'antonym',\n",
       " 'anu',\n",
       " 'anxiety',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'aoa',\n",
       " 'aokp',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'apex',\n",
       " 'api',\n",
       " 'apj',\n",
       " 'apk',\n",
       " 'apko',\n",
       " 'apna',\n",
       " 'apnake',\n",
       " 'apnar',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apostate',\n",
       " 'app',\n",
       " 'appadvice',\n",
       " 'appar',\n",
       " 'apparent',\n",
       " 'appbank',\n",
       " 'appchoices',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'append',\n",
       " 'appendix',\n",
       " 'appetite',\n",
       " 'applab',\n",
       " 'apple',\n",
       " 'appliaction',\n",
       " 'appliance',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'application√¢',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'applock',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appnomics',\n",
       " 'appnomicsstudio',\n",
       " 'appoday',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approved',\n",
       " 'approximately',\n",
       " 'approximates',\n",
       " 'apps',\n",
       " 'appservice',\n",
       " 'appsgeyser',\n",
       " 'appstorm',\n",
       " 'aprilia',\n",
       " 'apron',\n",
       " 'aquatic',\n",
       " 'aquino',\n",
       " 'ar',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabian',\n",
       " 'arabic',\n",
       " 'arabs',\n",
       " 'aramaic',\n",
       " 'aramex',\n",
       " 'arbi',\n",
       " 'arc',\n",
       " 'arcade',\n",
       " 'archer',\n",
       " 'archery',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'archive',\n",
       " 'archived',\n",
       " 'archiver',\n",
       " 'archivers',\n",
       " 'archiving',\n",
       " 'archvies',\n",
       " 'arctic',\n",
       " 'arduino',\n",
       " 'are',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'argentina',\n",
       " 'argentine',\n",
       " 'argondeviant',\n",
       " 'argued',\n",
       " 'ariana',\n",
       " 'ariary',\n",
       " 'aris',\n",
       " 'arise',\n",
       " 'arises',\n",
       " 'arising',\n",
       " 'arizona',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'armenian',\n",
       " 'armidale',\n",
       " 'armor',\n",
       " 'armoured',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arranging',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arrow',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'arts',\n",
       " 'artwork',\n",
       " 'aruban',\n",
       " 'aryan',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ascend',\n",
       " 'ascending',\n",
       " 'ascii',\n",
       " 'asf',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ashura',\n",
       " 'asia',\n",
       " 'ask',\n",
       " 'askar',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'asperger',\n",
       " 'assam',\n",
       " 'assassin',\n",
       " 'assault',\n",
       " 'assemble',\n",
       " 'assembled',\n",
       " 'assembling',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'assets',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assumes',\n",
       " 'assured',\n",
       " 'assures',\n",
       " 'asthma',\n",
       " 'astound',\n",
       " 'astounds',\n",
       " 'astro',\n",
       " 'astrology',\n",
       " 'astronaut',\n",
       " 'astronomy',\n",
       " 'asus',\n",
       " 'aswell',\n",
       " 'at',\n",
       " 'ataimpactforum',\n",
       " 'athlete',\n",
       " 'atlantic',\n",
       " 'atlantis',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'atomic',\n",
       " 'atp',\n",
       " 'attach',\n",
       " 'attaching',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacker',\n",
       " 'attacking',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attention',\n",
       " 'attest',\n",
       " 'attested',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'attributed',\n",
       " 'attributions',\n",
       " 'atuwawa',\n",
       " 'at√¢',\n",
       " 'au',\n",
       " 'aucde',\n",
       " 'auckland',\n",
       " 'aud',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audiobooks',\n",
       " 'audios',\n",
       " 'augmentation',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'autanm',\n",
       " 'authentic',\n",
       " 'authentication',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authoritative',\n",
       " 'authority',\n",
       " 'authorize',\n",
       " 'authorized',\n",
       " 'auto',\n",
       " 'autoclicks',\n",
       " 'autocollage',\n",
       " 'automagically',\n",
       " 'automate',\n",
       " 'automated',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automobile',\n",
       " 'automotive',\n",
       " 'autoplay',\n",
       " 'autosave',\n",
       " 'autoscroll',\n",
       " 'autumn',\n",
       " 'avaible',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avi',\n",
       " 'aviate',\n",
       " 'aviation',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'avoiding',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awaited',\n",
       " 'awaiting',\n",
       " 'awaits',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awas',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awesone',\n",
       " 'awg',\n",
       " 'awsome',\n",
       " 'ax',\n",
       " 'axe',\n",
       " 'axtel',\n",
       " 'ayah',\n",
       " 'ayat',\n",
       " 'azerbaijani',\n",
       " 'azha',\n",
       " 'azimuth',\n",
       " 'azn',\n",
       " 'aztec',\n",
       " 'azure',\n",
       " 'azwallpapersdev',\n",
       " 'ba',\n",
       " 'baad',\n",
       " 'baadshah',\n",
       " 'baazigar',\n",
       " 'baba',\n",
       " 'baby',\n",
       " 'bachata',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backgrounds',\n",
       " 'backing',\n",
       " 'backlit',\n",
       " 'backspa',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'badge',\n",
       " 'baekhyun',\n",
       " 'baffling',\n",
       " 'bafta',\n",
       " 'bag',\n",
       " 'bahag',\n",
       " 'bahamian',\n",
       " 'bahasa',\n",
       " 'bahrain',\n",
       " 'bahraini',\n",
       " 'baht',\n",
       " 'baidu',\n",
       " 'bait',\n",
       " 'bake',\n",
       " 'bakery',\n",
       " 'baking',\n",
       " 'bala',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balboa',\n",
       " 'balcony',\n",
       " 'baldi',\n",
       " 'balearic',\n",
       " 'ball',\n",
       " 'ballerina',\n",
       " 'ballet',\n",
       " 'balloob',\n",
       " 'balloon',\n",
       " 'ballora',\n",
       " 'bam',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bandit',\n",
       " 'bandwidth',\n",
       " 'banging',\n",
       " 'bangla',\n",
       " 'bangladesh',\n",
       " 'bangladeshi',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'bankruptcy',\n",
       " 'banner',\n",
       " 'bappa',\n",
       " 'bar',\n",
       " 'barbadian',\n",
       " 'barbell',\n",
       " 'barber',\n",
       " 'barbie',\n",
       " 'barcelona',\n",
       " 'barcode',\n",
       " 'barcodes',\n",
       " 'bare',\n",
       " 'bark',\n",
       " 'barking',\n",
       " 'barn',\n",
       " 'barnyard',\n",
       " 'barracuda',\n",
       " 'barrage',\n",
       " 'barrel',\n",
       " 'barren',\n",
       " 'barrier',\n",
       " 'basal',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'basra',\n",
       " 'bass',\n",
       " 'bat',\n",
       " 'bataenge',\n",
       " 'batane',\n",
       " 'batch',\n",
       " 'bathing',\n",
       " 'bathroom',\n",
       " 'batsman',\n",
       " 'battalion',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'battlefield',\n",
       " 'battleground',\n",
       " 'battleislandsgame',\n",
       " 'battleislandshq',\n",
       " 'battleship',\n",
       " 'battling',\n",
       " 'bay',\n",
       " 'bayern',\n",
       " 'bazooka',\n",
       " 'bbb',\n",
       " 'bbc',\n",
       " 'bbd',\n",
       " 'bbm',\n",
       " 'bbox',\n",
       " 'bc',\n",
       " 'bceao',\n",
       " 'bdt',\n",
       " 'beac',\n",
       " 'beach',\n",
       " 'beagle',\n",
       " 'beam',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'bears',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beautifies',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beautify',\n",
       " 'beautifying',\n",
       " 'beauty',\n",
       " 'beautyapps',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bedb',\n",
       " 'bedroom',\n",
       " 'bedside',\n",
       " 'bee',\n",
       " 'beekeeping',\n",
       " 'beer',\n",
       " 'beethoven',\n",
       " 'bega',\n",
       " 'began',\n",
       " 'beggar',\n",
       " 'begin',\n",
       " 'begining',\n",
       " 'beginner',\n",
       " 'beginning',\n",
       " 'begs',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behaves',\n",
       " 'behind',\n",
       " 'belarusian',\n",
       " 'belch',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believer',\n",
       " 'belize',\n",
       " 'bell',\n",
       " 'bellow',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belongs',\n",
       " 'beloved',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bench',\n",
       " 'benchmark',\n",
       " 'bender',\n",
       " 'beneath',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'bengal',\n",
       " 'bengali',\n",
       " 'bermudan',\n",
       " 'berry',\n",
       " 'berserker',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besiege',\n",
       " 'best',\n",
       " 'bestest',\n",
       " 'bestparking',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'betting',\n",
       " 'betty',\n",
       " 'between',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bezel',\n",
       " 'bgn',\n",
       " 'bhargo',\n",
       " 'bhd',\n",
       " 'bhur',\n",
       " 'bhutanese',\n",
       " 'bhuvah',\n",
       " 'bible',\n",
       " 'biblia',\n",
       " 'biblical',\n",
       " 'bicycle',\n",
       " 'bid',\n",
       " 'bidding',\n",
       " 'bif',\n",
       " 'big',\n",
       " 'bigballsc',\n",
       " 'bigeye',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigpondxxxxxx',\n",
       " 'bihar',\n",
       " 'bihu',\n",
       " 'bike',\n",
       " 'bilateral',\n",
       " 'bilingual',\n",
       " 'bill',\n",
       " 'billboard',\n",
       " 'billed',\n",
       " 'billing',\n",
       " 'billionaire',\n",
       " 'bin',\n",
       " 'binaural',\n",
       " 'bind',\n",
       " 'binding',\n",
       " 'bingo',\n",
       " 'bintang',\n",
       " 'bio',\n",
       " 'biography',\n",
       " 'biological',\n",
       " 'biology',\n",
       " 'biome',\n",
       " 'bionic',\n",
       " 'biopunk',\n",
       " 'biplane',\n",
       " 'bird',\n",
       " 'birr',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bisca',\n",
       " 'bit',\n",
       " 'bitcoin',\n",
       " 'bite',\n",
       " 'bitmango',\n",
       " 'bitmangogames',\n",
       " 'bizarre',\n",
       " 'bk',\n",
       " 'bl',\n",
       " 'black',\n",
       " 'blackberry',\n",
       " 'blackboard',\n",
       " 'blackbox',\n",
       " 'blackjack',\n",
       " 'blacklist',\n",
       " 'blackout',\n",
       " 'blackpink',\n",
       " 'blade',\n",
       " 'blake',\n",
       " 'blank',\n",
       " 'blast',\n",
       " 'blaster',\n",
       " 'blasting',\n",
       " 'blaze',\n",
       " 'ble',\n",
       " 'bleep',\n",
       " 'blemish',\n",
       " 'blend',\n",
       " 'blender',\n",
       " 'blending',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blink',\n",
       " 'blinker',\n",
       " 'blinking',\n",
       " 'blinkxxxxxx',\n",
       " 'bliss',\n",
       " 'blitar',\n",
       " 'blitz',\n",
       " 'bloat',\n",
       " 'bloated',\n",
       " 'bloatware',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10720"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5. TfidfTransformer to compute the IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfTransformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidfTransformer.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_list(doc):\n",
    "    # generate tfidf vector for given doc\n",
    "    tf_idf_vector = tfidfTransformer.transform(cv.transform([doc]))\n",
    "    \n",
    "    # Return a C00rdinate representation of this matrix\n",
    "    coo_matrix = tf_idf_vector.tocoo()\n",
    "    # sorted_items = sort_coo(coo_matrix)\n",
    "\n",
    "    # get Top-n index list\n",
    "    index_sort = np.argsort(coo_matrix.data)[-topn:]\n",
    "    \n",
    "    keyword_list = []\n",
    "    # extract keywords\n",
    "    for idx in index_sort[::-1]: \n",
    "        keyword_list.append(feature_names[coo_matrix.col[idx]])\n",
    "    \n",
    "    return keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Get consolidated keyword list for entire dataset\n",
    "\n",
    "# get topn = 10, keywords\n",
    "topn = 10\n",
    "df_pd_desc_final['description_keyword_list']=df_pd_desc_final['description_join'].apply(get_keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [movie, subscription, news, list, account, tv,...\n",
       "1      [knife, apple, score, progressive, blade, swor...\n",
       "2      [photo, lidow, subscription, instagram, leak, ...\n",
       "3      [vidstitch, video, instagram, combine, squeeze...\n",
       "4      [cat, hiding, item, place, unlikely, find, som...\n",
       "                             ...                        \n",
       "682    [mining, term, commit, alphabetical, determine...\n",
       "683    [hair, barber, salon, shop, cutting, kid, game...\n",
       "684    [volume, prayer, bukhari, ahadeeth, al, book, ...\n",
       "685    [lesson, english, phrasal, confusing, twominen...\n",
       "686    [galaxy, theme, plus, note, pro, smartphones, ...\n",
       "Name: description_keyword_list, Length: 687, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd_desc_final['description_keyword_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_final_spark = spark.createDataFrame(df_pd_desc_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topn):\n",
    "    df_desc_final_spark = df_desc_final_spark.withColumn(\"keyword-\"+str(i+1),df_desc_final_spark['description_keyword_list'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app_name',\n",
       " 'bundle',\n",
       " 'description',\n",
       " 'genres',\n",
       " 'os_platform',\n",
       " 'lang_code',\n",
       " 'description_clean',\n",
       " 'description_token',\n",
       " 'description_lemm',\n",
       " 'description_no_stop',\n",
       " 'description_join',\n",
       " 'description_keyword_list',\n",
       " 'keyword-1',\n",
       " 'keyword-2',\n",
       " 'keyword-3',\n",
       " 'keyword-4',\n",
       " 'keyword-5',\n",
       " 'keyword-6',\n",
       " 'keyword-7',\n",
       " 'keyword-8',\n",
       " 'keyword-9',\n",
       " 'keyword-10']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc_final_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final keyword spreadsheet to local\n",
    "df_desc_final = df_desc_final_spark.toPandas()\n",
    "df_desc_final.to_csv('desc_keyword.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BLOCK for testing individual sentence\n",
    "# # get the document that we want to extract from\n",
    "# test_idx = 3\n",
    "# doc_test = df_pd_desc_final['description_join'][test_idx]\n",
    "\n",
    "# # generate tfidf vector for given doc\n",
    "# tf_idf_vector = tfidfTransformer.transform(cv.transform([doc_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # Return a C00rdinate representation of this matrix\n",
    "# coo_matrix = tf_idf_vector.tocoo()\n",
    "# # sorted_items = sort_coo(coo_matrix)\n",
    "\n",
    "# # get Top-n list\n",
    "# index_sort = np.argsort(coo_matrix.data)[-10:]\n",
    "\n",
    "# # extract keywords, topn\n",
    "# print(\"Top-n keywords in the given document:\\n\")\n",
    "# for idx in index_sort[::-1]: \n",
    "\n",
    "#     print(feature_names[coo_matrix.col[idx]],\":\",coo_matrix.data[idx])\n",
    "\n",
    "# # keywords = extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "\n",
    "# # # print result\n",
    "# # print(\"Top-n keywords in the given document:\\n\")\n",
    "# # for k in keywords:\n",
    "# #     print(k,\":\",keywords[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- END --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_origin = df_pd_desc_final['description'][test_idx]\n",
    "# doc_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pd_desc_final['app_name'][test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pd_desc_final['genres'][test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm = tf_idf_vector.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sort_coo(coo_matrix):\n",
    "#     tuples = zip(coo_matrix.col,coo_matrix.data)\n",
    "#     return sorted(tuples,key=lambda x:x[1],reverse=True)\n",
    "\n",
    "# def extract_topn_from_vector(feature_names,sorted_items,topn):\n",
    "#     \"\"\"get the feature names according to the tf-idf score of top-n items\"\"\"\n",
    "    \n",
    "#     #use only top-n itmes\n",
    "#     sorted_items = sorted_items[:topn]\n",
    "    \n",
    "#     score_vals = []\n",
    "#     features_vals = []\n",
    "    \n",
    "#     # word index and corresponding tf-idf score\n",
    "#     for index,score in sorted_items:\n",
    "        \n",
    "#         #feature name and score\n",
    "#         score_vals.append(round(score,3))\n",
    "#         features_vals.append(feature_names[index])\n",
    "        \n",
    "#     # create a tuples of feature,score\n",
    "#     results = {}\n",
    "#     for index in range(len(features_vals)):\n",
    "#         results[features_vals[index]] = score_vals[index]\n",
    "        \n",
    "#     return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
